File for documenting potentially interesting things
---------------------------------------------------

Best 6 site 4 electron Hubbard transfer found
---------------------------------------------
midChristandl Hubbard 0.8891392269488438 58.021341053118554 64.33801859463422 6 2 2 0,1,0,1 5,4,5,4 119.24519848959174,126.52654346320944,3.0,126.52654346320944,119.24519848959174
Dual annealing got to around 0.75 relatively fast, took a few hours to get a sudden jump to around 0.84.
Basin hopping using the result dual annealing found relatively quickly improved the result to around 0.87-0.88ish, took a while to get to the value
listed here.

Potential code speed improvement
--------------------------------
Use sympy to find the hamiltonian matrix format for a given setup, and or possibly fidelity calculation format.
Sympy stands for symbolic python, meaning it can put variable names in matrix entries.
Convert the hamiltonian matrix to numpy using the command "lambdify", or fidelity calculation format to a function.
Code would now have a potentially longer time to get setup and running, but calculations that matter would be faster.

Best normalization?
-------------------
Is there a type of normalization that would make the code converge to a set of parameters better or faster?
Ideas: try setting time= pi/2; the time used in the Christandl paper. Or u= 1 or 10.

High t values
-------------
Most sets of parameters produced give really high t values (at least using midChristandl normalization so far).
Was able to get code to converge when t values were constrained to relatively low values, but this took a lot longer.
Ideas: maybe there are not really many (or maybe there is actually just one) parameter sets for perfect transfer in this high t range, they are just 
really easy to find. Could be worth looking at graphs of the form (sum(t), fidelity).

High u and t values
-------------------
Similar to the previous thing mentioned.
u and time values found tend to be relatively high, but not as high as t values.
Ideas: from looking at data, I have a feeling that there might be a decent amount of perturbation room for u and time values while still keeping
fidelity high. This would result in the appearance of many parameters sets with varying u and time values all around the same fidelity.
This might suggest looking at (as mentioned before) (sum(t), fidelity) graphs and setting time= pi/2 or a similar normalization for u.




